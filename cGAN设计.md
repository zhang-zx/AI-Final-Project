# cGAN设计

## GAN的提出背景与基本原理

&emsp; &emsp; 机器学习的模型大体上可以分为两类，生成模型与判别模型。其中，判别模型要求输入变量$x$，通过某种模型来预测$p(y|x)$。但是，生成模型是给定某些隐含信息，从而生成随机数据。这样的学习方式的困难之处在于，人们对生成结果的期望是一种无法使用数学公理化定义的范式。但是对于这种难以公理化的任务来说，判别模型已经有了很好地解决方式。这种将生成模型与判别模型进行结合来进行更好的生成的方式就是GAN。GAN（Generative Adversarial Networks）是GoodFellow在2014年的论文中提出的一种思想，要求使用generator学习将一个已知的高斯分布映射到更高维的空间中去拟合真实图像的分布。

&emsp; &emsp; 生成对抗网络主要由生成器$G$和判别器$D$构成，在训练过程中$D$要尽可能使$D(G(z)) = 0, D(x_{real}) = 1$，而$G$要尽可能使得$D(G(z)) = 1$，这样就构成了生成对抗网络中的对抗部分。

&emsp; &emsp; GAN具有很好地应用前景，从目前的文献来看，GAN 在图像上的应用主要是往图像修改方向发展。涉及的图像修改方向主要包括：单图像超分辨率、交互式图像生成、图像编辑、图像到图像的翻译等。GAN在NLP方向上也有着很好地应用前景。目前来说 GAN 在 NLP 上的应用可以分为两类：生成文本、根据文本生成图像。其中，生成文本包括两种：根据隐向量（噪声）生成一段文本；对话生成。

## 朴素GAN中存在的缺陷

目前朴素GAN中主要存在以下几点问题：

- non-convergence：目前所有的理论都认为 GAN 应该在纳什均衡上有卓越的表现，但梯度下降只有在凸函数的情况下才能保证实现纳什均衡。当博弈双方都由神经网络表示时，在没有实际达到均衡的情况下，让它们永远保持对自己策略的调整是可能的。
- collapse problem：GAN模型被定义为极小极大问题，没有损失函数，在训练过程中很难区分是否正在取得进展。GAN的学习过程可能发生崩溃问题，生成器开始退化，总是生成同样的样本点，无法继续学习。当生成模型崩溃时，判别模型也会对相似的样本点指向相似的方向，训练无法继续。
- 模型过于自由不可控：与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，即不需要formulate $p(x)$，而是使用一种分布直接进行采样，从而真正达到理论上可以完全逼近真实数据，这也是GAN最大的优势。然而，这种不需要预先建模的方法缺点是太过自由了，对于较大的图片，较多的 pixel的情形，基于简单 GAN 的方式就不太可控了。

## 项目设计

&emsp; &emsp; 基于上面提出的，与其他生成式模型相比，GAN这种竞争的方式不再要求一个假设的数据分布，从而导致过于自由的问题，有了CGAN的提出。在[Conditional Generative Adversarial Nets（CGAN）[Mirza M, Osindero S. Conditional]](https://arxiv.org/abs/1411.1784)这篇文章中，作者提出了在生成模型和判别模型的建设中引入条件变量y，使用额外的信息增加条件，从而指导数据生成的过程。如果条件变量y是类别标签，可以看做CGAN 是把纯无监督的 GAN 变成有监督的模型的一种改进。CGAN的简要结构如下图所示![image-20180529185649676](/Users/zhixingzhang/Documents/大三下/AI-Final-Project/media/image-20180529185649676.png)

&emsp; &emsp; 在我们的项目中，我们主要在pytorch的框架中实现了CGAN并使用FashionMNIST数据集进行了实验。我们的测试环境为：配置了4核心Intel(R) Core(TM) i5-7500 CPU @ 3.40GHz，24GRAM，GTX 1080Ti的Ubuntu16.04极客云服务器。使用Python3.6，pytorch0.3.1进行编程。我们的模型以及相应的参数如下图：![demo](/Users/zhixingzhang/Documents/大三下/AI-Final-Project/media/demo.jpeg)